
from nltk.tokenize import sent_tokenize

data='This is an example sent. The sentence splitter will split on sent markers. Ohh really !!'
print("set_::", sent_tokenize(data))