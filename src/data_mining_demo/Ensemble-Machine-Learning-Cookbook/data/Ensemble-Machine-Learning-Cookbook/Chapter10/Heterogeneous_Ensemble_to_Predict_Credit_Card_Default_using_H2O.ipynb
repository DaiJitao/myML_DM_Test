{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtxImZQFDZks"
   },
   "outputs": [],
   "source": [
    "! pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlH0wQpOBb9k"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn import tree\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NaqupSXBrmX"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BgXwBHfSC3x0"
   },
   "outputs": [],
   "source": [
    "#Initialize H2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6sqvkdYNxWY"
   },
   "outputs": [],
   "source": [
    "# Reading dataset from Google drive\n",
    "df_creditcarddata = h2o.import_file(\"/content/drive/My Drive/Colab Notebooks/UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pg0ZLvj5zr5E"
   },
   "outputs": [],
   "source": [
    "type(df_creditcarddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2UeRv12OrVf"
   },
   "outputs": [],
   "source": [
    "df_creditcarddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VvHlES5DO8pu"
   },
   "outputs": [],
   "source": [
    "#check dimensions of the data\n",
    "df_creditcarddata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gc1AEyhuPHqv"
   },
   "outputs": [],
   "source": [
    "df_creditcarddata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XdCrZCd2fk9"
   },
   "outputs": [],
   "source": [
    "df_creditcarddata.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MN77jXB4PJzl"
   },
   "outputs": [],
   "source": [
    "#Count for the response var\n",
    "df_creditcarddata['default.payment.next.month'].table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYYi0deaPpE1"
   },
   "outputs": [],
   "source": [
    "df_creditcarddata = df_creditcarddata.drop([\"ID\"], axis = 1) \n",
    "df_creditcarddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FJPHjdLQ5jV"
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "df_creditcarddata[['AGE','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6', 'LIMIT_BAL']].as_data_frame().hist(figsize=(20,20))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuCIlD6IT23e"
   },
   "outputs": [],
   "source": [
    "# Defaulters by Gender\n",
    "columns = [\"default.payment.next.month\",\"SEX\"]\n",
    "default_by_gender = df_creditcarddata.group_by(by=columns).count(na =\"all\")\n",
    "print(default_by_gender.get_frame())\n",
    "\n",
    "# Defaulters by  education\n",
    "columns = [\"default.payment.next.month\",\"EDUCATION\"]\n",
    "default_by_education = df_creditcarddata.group_by(by=columns).count(na =\"all\")\n",
    "print(default_by_education.get_frame())\n",
    "\n",
    "# Defaulters by MARRIAGE\n",
    "columns = [\"default.payment.next.month\",\"MARRIAGE\"]\n",
    "default_by_marriage = df_creditcarddata.group_by(by=columns).count(na =\"all\")\n",
    "print(default_by_marriage.get_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAK1Yqn3Urev"
   },
   "outputs": [],
   "source": [
    "# Convert the categorical variables into factors\n",
    "\n",
    "df_creditcarddata['SEX'] = df_creditcarddata['SEX'].asfactor()\n",
    "df_creditcarddata['EDUCATION'] = df_creditcarddata['EDUCATION'].asfactor()\n",
    "df_creditcarddata['MARRIAGE'] = df_creditcarddata['MARRIAGE'].asfactor()\n",
    "df_creditcarddata['PAY_0'] = df_creditcarddata['PAY_0'].asfactor()\n",
    "df_creditcarddata['PAY_2'] = df_creditcarddata['PAY_2'].asfactor()\n",
    "df_creditcarddata['PAY_3'] = df_creditcarddata['PAY_3'].asfactor()\n",
    "df_creditcarddata['PAY_4'] = df_creditcarddata['PAY_4'].asfactor()\n",
    "df_creditcarddata['PAY_5'] = df_creditcarddata['PAY_5'].asfactor()\n",
    "df_creditcarddata['PAY_6'] = df_creditcarddata['PAY_6'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c738WjQ4UA61"
   },
   "outputs": [],
   "source": [
    "df_creditcarddata.types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDaneP0dVez-"
   },
   "outputs": [],
   "source": [
    "# Also, encode the binary response variable as a factor\n",
    "df_creditcarddata['default.payment.next.month'] = df_creditcarddata['default.payment.next.month'].asfactor()  \n",
    "df_creditcarddata['default.payment.next.month'].levels() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugqs25bOVk0f"
   },
   "outputs": [],
   "source": [
    "# Define predictors manually\n",
    "predictors = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3',\\\n",
    "              'PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4',\\\n",
    "              'BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']\n",
    "\n",
    "target = 'default.payment.next.month'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0juOGH4KT-rH"
   },
   "outputs": [],
   "source": [
    "# Split the H2O data frame into training/test sets\n",
    "\n",
    "# using 70% for training\n",
    "# using the rest 30% for test evaluation\n",
    "\n",
    "splits = df_creditcarddata.split_frame(ratios=[0.7], seed=1) \n",
    "\n",
    "train = splits[0]\n",
    "test = splits[1] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJ-i8EeFW2_q"
   },
   "source": [
    "**GENERALIZED LINEAR MODEL (Defaut Settings)**\n",
    "\n",
    "STANDARDIZATION is enabled by default\n",
    "\n",
    "GLM with default setting\n",
    "GLM using lmbda search\n",
    "GLM using Grid search\n",
    "GLM WITH DEFAULT SETTINGS\n",
    "\n",
    "Logistic Regression (Binomial Family)\n",
    "\n",
    "H2O's GLM has the \"family\" argument, where the family is 'binomial' if the data is categorical 2 levels/classes or binary (Enum or Int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYJmb2vmTzS-"
   },
   "outputs": [],
   "source": [
    "GLM_default_settings = H2OGeneralizedLinearEstimator(family='binomial', \\\n",
    "                                            model_id='GLM_default',nfolds = 10, \\\n",
    "                                            fold_assignment = \"Modulo\", \\\n",
    "                                            keep_cross_validation_predictions = True)\n",
    "\n",
    "GLM_default_settings.train(x = predictors, y = target, training_frame = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCq6uLjSXJtf"
   },
   "source": [
    "### **GLM WITH LAMBDA SEARCH**\n",
    "\n",
    "The model parameter, lambda, controls the amount of regularization in a GLM model\n",
    "Setting  lambda_search = True gives us optimal lambda value for the regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydcLuB4BFoOh"
   },
   "outputs": [],
   "source": [
    "GLM_regularized = H2OGeneralizedLinearEstimator(family='binomial', model_id='GLM', \\\n",
    "                                                lambda_search=True, nfolds = 10, \\\n",
    "                                                fold_assignment = \"Modulo\", \\\n",
    "                                                keep_cross_validation_predictions = True)\n",
    "\n",
    "GLM_regularized.train(x = predictors, y = target,training_frame = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qGGzY7zLOEuY"
   },
   "source": [
    "### **GLM WITH GRID SEARCH**\n",
    "\n",
    "GLM needs to find the optimal values of the regularization parameters α and λ\n",
    "lambda: controls the amount of regularization, when set to 0 it gets disabled\n",
    "\n",
    "alpha : controls the distribution between lasso & ridge regression penalties.\n",
    "\n",
    "random grid search: H2o supports 2 types of grid search, cartesian and random. We make use of the random as the search criteria for faster computation\n",
    "\n",
    "Stopping metric: we specify the metric used for early stopping. AUTO takes log loss as default\n",
    "\n",
    "source: http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/lambda.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vf8iCf8ETXBg"
   },
   "outputs": [],
   "source": [
    "hyper_parameters = { 'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                     'lambda': [0.001, 0.01, 0.1] }\n",
    "search_criteria = { 'strategy': \"RandomDiscrete\", \n",
    "                    'stopping_metric': \"AUTO\",\n",
    "                    'stopping_rounds': 5}\n",
    "\n",
    "GLM_grid_search = H2OGridSearch(H2OGeneralizedLinearEstimator(family='binomial', \\\n",
    "                  nfolds = 10, fold_assignment = \"Modulo\", \\\n",
    "                  keep_cross_validation_predictions = True),\\\n",
    "                  hyper_parameters, grid_id=\"GLM_grid\", search_criteria=search_criteria)\n",
    "\n",
    "GLM_grid_search.train(x= predictors,y= target, training_frame=train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQbq25GCzaQN"
   },
   "source": [
    "### Get the grid results, sorted by validation AUC\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zUUWhlpTTuo"
   },
   "outputs": [],
   "source": [
    "# Get the grid results, sorted by validation AUC\n",
    "GLM_grid_sorted = GLM_grid_search.get_grid(sort_by='auc', decreasing=True)\n",
    "GLM_grid_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HK5WbU3-5aP4"
   },
   "outputs": [],
   "source": [
    "# Extract the best model from random grid search\n",
    "Best_GLM_model_from_Grid = GLM_grid_sorted.model_ids[0]\n",
    "\n",
    "#model performance\n",
    "Best_GLM_model_from_Grid = h2o.get_model(Best_GLM_model_from_Grid)\n",
    "print(Best_GLM_model_from_Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKp3rnlZ1GFT"
   },
   "source": [
    "### RF WITH DEFAULT SETTINGS\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCWCsIWeRL1e"
   },
   "outputs": [],
   "source": [
    "# Build a RF model with default settings\n",
    "RF_default_settings = H2ORandomForestEstimator(model_id = 'RF_D',\\\n",
    "                                nfolds = 10, fold_assignment = \"Modulo\", \\\n",
    "                                keep_cross_validation_predictions = True)\n",
    "\n",
    "# Use train() to build the model\n",
    "RF_default_settings.train(x = predictors, y = target, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBCX-kPe2Tjm"
   },
   "outputs": [],
   "source": [
    "#Let's see the default parameters that RF model utilizes:\n",
    "RF_default_settings.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_9zLvChSBM3l"
   },
   "source": [
    "### RF with GRID SEARCH to extract the best model\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAFFKV4iBPJY"
   },
   "outputs": [],
   "source": [
    "hyper_params = {'sample_rate':[0.7,0.9],\n",
    "                'col_sample_rate_per_tree': [0.8, 0.9],\n",
    "                'max_depth': [3, 5, 9],\n",
    "                'ntrees': [200, 300, 400]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruDDElyCBRUc"
   },
   "outputs": [],
   "source": [
    "RF_grid_search = H2OGridSearch(H2ORandomForestEstimator(nfolds = 10, \\\n",
    "                             fold_assignment = \"Modulo\", \\\n",
    "                             keep_cross_validation_predictions = True, \\\n",
    "                             stopping_metric = 'AUC',stopping_rounds = 5), \\\n",
    "                             hyper_params = hyper_params, \\\n",
    "                             grid_id= 'RF_gridsearch')\n",
    "\n",
    "# Use train() to start the grid search\n",
    "RF_grid_search.train(x = predictors, y = target, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP_M4DF4B185"
   },
   "outputs": [],
   "source": [
    "# Sort the grid models\n",
    "RF_grid_sorted = RF_grid_search.get_grid(sort_by='auc', decreasing=True)\n",
    "print(RF_grid_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gcG5UqcC-g6"
   },
   "outputs": [],
   "source": [
    "# Extract the best model from random grid search\n",
    "Best_RF_model_from_Grid = RF_grid_sorted.model_ids[0]\n",
    "\n",
    "# Model performance\n",
    "Best_RF_model_from_Grid = h2o.get_model(Best_RF_model_from_Grid) \n",
    "print(Best_RF_model_from_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjNwnjiuK7bO"
   },
   "outputs": [],
   "source": [
    "GBM_default_settings = H2OGradientBoostingEstimator(model_id = 'GBM_default', \\\n",
    "                       nfolds = 10, \\\n",
    "                       fold_assignment = \"Modulo\", \\\n",
    "                       keep_cross_validation_predictions = True)\n",
    "\n",
    "# Use train() to build the model\n",
    "GBM_default_settings.train(x = predictors, y = target, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njI-1xh_UUdg"
   },
   "outputs": [],
   "source": [
    "hyper_params = {'learn_rate': [0.001,0.01, 0.1],\n",
    "                'sample_rate': [0.8, 0.9],\n",
    "                'col_sample_rate': [0.2, 0.5, 1],\n",
    "                'max_depth': [3, 5, 9],\n",
    "                'ntrees' : [100, 200, 300]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ja_fZQIT-Z0"
   },
   "outputs": [],
   "source": [
    "GBM_grid_search = H2OGridSearch(H2OGradientBoostingEstimator(nfolds = 10, \\\n",
    "                        fold_assignment = \"Modulo\", \\\n",
    "                        keep_cross_validation_predictions = True,\\\n",
    "                        stopping_metric = 'AUC', stopping_rounds = 5),\n",
    "                        hyper_params = hyper_params, grid_id= 'GBM_Grid')\n",
    "\n",
    "# Use train() to start the grid search\n",
    "GBM_grid_search.train(x = predictors, y = target, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lO9ypTdWoJz"
   },
   "outputs": [],
   "source": [
    "# Sort and show the grid search results\n",
    "GBM_grid_sorted = GBM_grid_search.get_grid(sort_by='auc', decreasing=True)\n",
    "print(GBM_grid_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8YwXJ0MWwa4"
   },
   "outputs": [],
   "source": [
    "# Extract the best model from random grid search\n",
    "Best_GBM_model_from_Grid = GBM_grid_sorted.model_ids[0]\n",
    "\n",
    "Best_GBM_model_from_Grid = h2o.get_model(Best_GBM_model_from_Grid) \n",
    "print(Best_GBM_model_from_Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJHdURWvamMP"
   },
   "source": [
    "### STACKED ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsJc2ppqalgV"
   },
   "outputs": [],
   "source": [
    "# list the best models from each grid\n",
    "all_models = [Best_GLM_model_from_Grid, Best_RF_model_from_Grid, Best_GBM_model_from_Grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EH4xpF3caz-L"
   },
   "outputs": [],
   "source": [
    "# Set up Stacked Ensemble\n",
    "ensemble = H2OStackedEnsembleEstimator(model_id = \"ensemble\", base_models = all_models, metalearner_algorithm = \"deeplearning\")\n",
    "\n",
    "# uses GLM as the default metalearner\n",
    "ensemble.train(y = target, training_frame = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8S8xb9mQ7z4"
   },
   "source": [
    "### Checking model performance of all base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZwQintiO-9F"
   },
   "outputs": [],
   "source": [
    "# Checking the model performance for all GLM models built\n",
    "\n",
    "model_perf_GLM_default = GLM_default_settings.model_performance(test)\n",
    "\n",
    "model_perf_GLM_regularized = GLM_regularized.model_performance(test)\n",
    "\n",
    "model_perf_Best_GLM_model_from_Grid = Best_GLM_model_from_Grid.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCQlWb0VPILV"
   },
   "outputs": [],
   "source": [
    "# Checking the model performance for all RF models built\n",
    "\n",
    "\n",
    "model_perf_RF_default_settings = RF_default_settings.model_performance(test)\n",
    "\n",
    "model_perf_Best_RF_model_from_Grid = Best_RF_model_from_Grid.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kIJFe7aPZz0"
   },
   "outputs": [],
   "source": [
    "# Checking the model performance for all GBM models built\n",
    "\n",
    "model_perf_GBM_default_settings = GBM_default_settings.model_performance(test)\n",
    "\n",
    "model_perf_Best_GBM_model_from_Grid = Best_GBM_model_from_Grid.model_performance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__WMwmWUQTpj"
   },
   "source": [
    "### Best AUC from the base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xx_ooofOQWhY"
   },
   "outputs": [],
   "source": [
    "# Best AUC from the base learner models\n",
    "best_auc = max(model_perf_GLM_default.auc(), model_perf_GLM_regularized.auc(), \\\n",
    "               model_perf_Best_GLM_model_from_Grid.auc(), \\\n",
    "               model_perf_RF_default_settings.auc(), \\\n",
    "               model_perf_Best_RF_model_from_Grid.auc(), \\\n",
    "               model_perf_GBM_default_settings.auc(), \\\n",
    "               model_perf_Best_GBM_model_from_Grid.auc())\n",
    "\n",
    "print(\"Best AUC out of all the models performed: \", format(best_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDIYzuzUQyEB"
   },
   "source": [
    "### AUC from the Ensemble Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b68JlOYzMJgX"
   },
   "outputs": [],
   "source": [
    "# Eval ensemble performance on the test data\n",
    "Ensemble_model = ensemble.model_performance(test)\n",
    "Ensemble_model = Ensemble_model.auc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5Kc01MDbU9d"
   },
   "outputs": [],
   "source": [
    "print(Ensemble_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Heterogeneous Ensemble to Predict Credit Card Default using H2O.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
